+++
title = "ECiDA"
tagline = "Evolutionaire Veranderingen in Data Analyse "
+++
Het “Internet of Things” groeit: steeds meer sensoren en actuatoren zijn verbonden met het internet, en gezamenlijk produceren deze apparaten een enorme hoeveelheid gegevens. Met behulp van data science kunnen deze gegevens verwerkt en geanalyseerd worden. Het verwerken van een dusdanige hoeveelheid gegevens vereist een gedistribueerd cluster van servers, zodat gegevens snel en gelijktijdig verwerkt kunnen worden. Dit wordt ook wel de data science infrastructuur genoemd. De benodigde stappen, ofwel het algoritme, voor het verwerken van de gegevens worden vooraf gedefinieerd en geïmplementeerd in een zogenoemd data processing framework. Een dergelijk framework zorgt ervoor dat de servers in het cluster de vooraf gedefinieerde stappen gelijktijdig kunnen uitvoeren. Wanneer er wijzigingen plaatsvinden in het algoritme moet de gehele applicatie opnieuw worden gestart. De impact hiervan is enorm, met name voor real-time gegevensstromen die 24x7 beschikbaar moeten zijn; bij een herstart raken de tussentijdse berekeningen verloren en deze moeten vervolgens opnieuw berekend worden, en er vindt een onderbreking plaats in de dienstverlening.

## Wijzigingen
Wijzigingen in het algoritme zijn niet ongewoon, de manier waarop data science werkt leidt vaak tot experimentele veranderingen in het algoritme. In dit project onderzoeken wij de mogelijkheid om een data science infrastructuur te realiseren waarbij verandering en evolutie centraal staan. Deze vernieuwende architectuur zorgt ervoor dat wijzigingen in het algoritme gemaakt kunnen worden zonder dat de gehele applicatie gestopt en herstart moet worden. Het gevolg is dat er geen onderbrekingen plaatsvinden in de gegevensstromen. Dit werk borduurt voort op onder andere een onderzoek uitgevoerd door TNO, waarbij een eenvoudig prototype voor het real-time wijzigen van een algoritme is ontwikkeld.

iHet onderzoek zal gevalideerd worden op basis van drie verschillende use-cases; 1) het toezicht houden op en automatiseren van de waterdistributie in samenwerking met Vitens (topsector Water), 2) het voorspellen en handhaven van de waterkwaliteit in samenwerking met Vitens (topsector Life Sciences & Health) en 3) de betrouwbaarheid van de constructie van waterleidingen in samenwerking met TNO (topsector HTSM/Smart
Industry). Alle use-cases zijn gerelateerd aan de kwaliteit van de watervoorziening, hebben data science centraal staan, en vereisen een infrastructuur die de evolutie van algoritmen ondersteunt.
Op dit moment ondergaat de watervoorziening een transformatie op het gebied van informatietechnologie. Dankzij de introductie van nieuwe sensoren, die real-time gegevens verzamelen over de watervoorziening en de kwaliteit ervan, ontstaat de mogelijkheid om data science op grote schaal toe te passen. Het resultaat is dat de watervoorziening verder geautomatiseerd kan worden, denk bijvoorbeeld aan het autonoom aansturen van pompen of kleppen welke voorheen met de hand bediend werden. Ook kan het proces om de kwaliteit van grondwater te meten worden verbeterd door de grote hoeveelheid gegevens die beschikbaar zullen zijn. Daarnaast ontstaat de mogelijkheid om predictief onderhoud uit te voeren, omdat er sensoren beschikbaar zijn die toezicht houden op de actuele staat van de waterleidingen. Om dit werkelijkheid te laten worden is er behoefte aan een flexibele en efficiënte data science infrastructuur, een infrastructuur die het mogelijk maakt om te experimenten en regelmatig wijzigingen door te voeren, een infrastructuur waarbij evolutie centraal staat.
